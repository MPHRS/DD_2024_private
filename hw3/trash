import json
import csv

# Загружаем параметры из params.json
with open("params.json") as f:
    params = json.load(f)

# Загружаем данные из samples.csv
samples = []
with open("samples.csv") as csvfile:
    reader = csv.DictReader(csvfile)
    for row in reader:
        samples.append(row)

# Правило all (если нужно собрать все файлы)
rule all:
    input:
        expand("test_output/abricate/{sample_id}/result.txt", sample_id=[s["sample_id"].split('.')[0] for s in samples])

# FastQC
rule fastqc:
    input:
        read_1 = lambda wildcards: "test_input/" + next(s["read_1"] for s in samples if s["sample_id"] == wildcards.sample_id),
        read_2 = lambda wildcards: "test_input/" + next(s["read_2"] for s in samples if s["sample_id"] == wildcards.sample_id)
    output:
        html1 = "test_output/fastqc/{sample_id}_read1_fastqc.html",
        html2 = "test_output/fastqc/{sample_id}_read2_fastqc.html"
    log:
        log1 = "test_output/fastqc/{sample_id}_read1_fastqc.log",
        log2 = "test_output/fastqc/{sample_id}_read2_fastqc.log"
    conda:
        "/home/mhprs/miniconda3/envs/DD_fastqc_h"
    params:
        threads = params["global_params"]["threads"]
    shell:
        """
        fastqc -t {params.threads} {input.read_1} {input.read_2} -o test_output/fastqc
        mv test_output/fastqc/{wildcards.sample_id}_read1_fastqc.html {output.html1}
        mv test_output/fastqc/{wildcards.sample_id}_read2_fastqc.html {output.html2}
        mv test_output/fastqc/{wildcards.sample_id}_read1_fastqc.log {log.log1}
        mv test_output/fastqc/{wildcards.sample_id}_read2_fastqc.log {log.log2}
        """
# SPAdes
rule spades:
    input:
        read_1 = lambda wildcards: next(s["read_1"] for s in samples if s["sample_id"] == wildcards.sample_id),
        read_2 = lambda wildcards: next(s["read_2"] for s in samples if s["sample_id"] == wildcards.sample_id)
    output:
        assembly = "test_output/spades/{sample_id}/"
    conda:
        "/home/mhprs/miniconda3/envs/DD_spades"
    params:
        threads = params["spades"]["threads"],
        memory = params["spades"]["memory"],  # memory в формате "8G"
        memory_mb = int(params["spades"]["memory"].replace('G', '')) * 1024  # Преобразуем в МБ
    shell:
        """
        spades.py -1 {input.read_1} -2 {input.read_2} -o {output.assembly} --threads {params.threads} --memory {params.memory_mb}
        """


# Quast
rule quast:
    input:
        contigs = "test_output/spades/{sample_id}/contigs.fasta",
        scaffolds = "test_output/spades/{sample_id}/scaffolds.fasta"
    output:
        report_dir_quast = directory("test_output/quast/{sample_id}/")
    conda:
        "/home/mhprs/miniconda3/envs/DD_quast"
    params:
        reference = params["quast"]["reference"]
    shell:
        """
        quast -o {output.report_dir_quast} {input.contigs} {input.scaffolds}
        """

# Prokka
rule prokka:
    input:
        assembly = "test_output/spades/{sample_id}/scaffolds.fasta"
    output:
        gff = "{params['prokka']['outdir']}/{sample_id}.gff"
    conda:
        "/home/mhprs/miniconda3/envs/DD_prokka_h"
    params:
        genus = params["prokka"]["genus"],
        outdir = params["prokka"]["outdir"]
    shell:
        """
        prokka --outdir {params.outdir} --prefix {sample_id} --genus {params.genus} {input.assembly} --force
        """

# Abricate
rule abricate:
    input:
        gff = "{params['prokka']['outdir']}/{sample_id}.gff",
        contigs = "test_output/spades/{sample_id}/contigs.fasta"
    output:
        abricate_result = "test_output/abricate/{sample_id}/result.txt"
    conda:
        "/home/mhprs/miniconda3/envs/DD_abricate_h"
    params:
        database = params["abricate"]["database"]
    shell:
        """
        abricate --db {params.database} {input.gff} > {output.abricate_result}
        """
